{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c7b5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d443652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46427, 16)\n"
     ]
    }
   ],
   "source": [
    "def read_data():\n",
    "    '''Import data from the data directory\n",
    "\n",
    "    Inputs: None\n",
    "    Returns: df. Pandas dataframe\n",
    "    '''\n",
    "    return pd.read_csv(\"../data/dev_data_nyc_airbnb.csv\")\n",
    "\n",
    "df = read_data()\n",
    "print(df.shape)\n",
    "# print(df.head(5))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49d511",
   "metadata": {},
   "source": [
    "### Dummy continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66a020ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n",
      "(20000,)\n",
      "(6427,)\n",
      "(20000,)\n",
      "(20000,)\n",
      "(6427,)\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels\n",
    "y = df['price']\n",
    "X = df[['minimum_nights','number_of_reviews','availability_365','reviews_per_month']]\n",
    "\n",
    "# Fill missings with mean\n",
    "my_imputer = SimpleImputer(strategy=\"mean\")\n",
    "X = my_imputer.fit_transform(X)\n",
    "\n",
    "# Initialise the model (Random forest)\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X,y)\n",
    "\n",
    "# Score the training data\n",
    "y_p = rf_model.predict(X)\n",
    "\n",
    "# Split into TTV\n",
    "y_train = y[:20000] \n",
    "y_valid = y[20000:40000]\n",
    "y_test = y[40000:]\n",
    "y_train_p = y_p[:20000] \n",
    "y_valid_p = y_p[20000:40000]\n",
    "y_test_p = y_p[40000:]\n",
    "\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train_p.shape)\n",
    "print(y_valid_p.shape)\n",
    "print(y_test_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a85bd08",
   "metadata": {},
   "source": [
    "### Dummy binary classifier data\n",
    "Just generate a number of 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1020f029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "(2000,)\n",
      "(1000,)\n",
      "(2000,)\n",
      "(2000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Get dummy binary classifier data\n",
    "import random\n",
    "y = [random.randint(0,1) for i in range(5000)]\n",
    "y_p = [random.randint(0,1) for i in range(5000)]\n",
    "y = np.array(y)\n",
    "y_p = np.array(y_p)\n",
    "\n",
    "# Split into TTV\n",
    "y_train = y[:2000] \n",
    "y_valid = y[2000:4000]\n",
    "y_test = y[4000:]\n",
    "y_train_p = y_p[:2000] \n",
    "y_valid_p = y_p[2000:4000]\n",
    "y_test_p = y_p[4000:]\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train_p.shape)\n",
    "print(y_valid_p.shape)\n",
    "print(y_test_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64d84f4",
   "metadata": {},
   "source": [
    "### Dummy multi-level classifier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d7f7d2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d' 'a' 'b' 'c' 'a' 'a' 'c' 'c' 'a' 'd']\n",
      "['b' 'd' 'c' 'e' 'd' 'c' 'c' 'e' 'c' 'b']\n",
      "(2000,)\n",
      "(2000,)\n",
      "(1000,)\n",
      "(2000,)\n",
      "(2000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Get dummy binary classifier data\n",
    "import random\n",
    "levels = ['a','b','c','d','e']\n",
    "y = [levels[random.randint(0,4)] for i in range(5000)]\n",
    "y_p = [levels[random.randint(0,4)] for i in range(5000)]\n",
    "y = np.array(y)\n",
    "y_p = np.array(y_p)\n",
    "\n",
    "print(y[:10])\n",
    "print(y_p[:10])\n",
    "\n",
    "# Split into TTV\n",
    "y_train = y[:2000] \n",
    "y_valid = y[2000:4000]\n",
    "y_test = y[4000:]\n",
    "y_train_p = y_p[:2000] \n",
    "y_valid_p = y_p[2000:4000]\n",
    "y_test_p = y_p[4000:]\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train_p.shape)\n",
    "print(y_valid_p.shape)\n",
    "print(y_test_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5ed73",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2ca0ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error,\n",
    "                            accuracy_score, precision_score, recall_score, f1_score,\n",
    "                            confusion_matrix, classification_report\n",
    "\n",
    "def perf_mets(\n",
    "        model_type = \"reg\", \n",
    "        y_train = None, y_train_p = None, \n",
    "        y_valid = None, y_valid_p = None,\n",
    "        y_test = None, y_test_p = None\n",
    "):\n",
    "    '''Get the high level performance metrics for a model\n",
    "    \n",
    "    input:\n",
    "        model_type: Str (default = \"reg\"). Type of model {reg, binary_class, \"multi_class\"}\n",
    "        y_train: Pandas series or numpy array (default = None). Traing data labels\n",
    "        y_train_p: Pandas series or numpy array (default = None). Training data predictions\n",
    "        y_valid: Pandas series or numpy array (default = None). Validation data label\n",
    "        y_valid_p: Pandas series or numpy array (default = None). Validation data predictions            \n",
    "        y_test: Pandas series or numpy array (default = None). Validation data labels\n",
    "        y_test_p: Pandas series or numpy array (default = None). Training data predictions\n",
    "        \n",
    "        In the case of a regressor the iterables represent probabilities\n",
    "        In the case of a classifier (binary or multileve) the iterables represent class memberships \n",
    "        \n",
    "    output:\n",
    "        None\n",
    "    '''\n",
    "    print(\"Headline performance metrics\")\n",
    "\n",
    "    if model_type == \"reg\":        \n",
    "        print(\"Model R2\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(f\"\\tTrain:\\t\\t{r2_score(y_train, y_train_p):.4f}\")\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(f\"\\tValidation:\\t{r2_score(y_valid, y_valid_p):.4f}\")\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(f\"\\tTest:\\t\\t{r2_score(y_test, y_test_p):.4f}\")\n",
    "            \n",
    "        print(\"MAE\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(f\"\\tTrain:\\t\\t{mean_absolute_error(y_train, y_train_p):.4f}\")\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(f\"\\tValidation:\\t{mean_absolute_error(y_valid, y_valid_p):.4f}\")\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(f\"\\tTest:\\t\\t{mean_absolute_error(y_test, y_test_p):.4f}\")\n",
    "            \n",
    "        print(\"MSE\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(f\"\\tTrain:\\t\\t{mean_squared_error(y_train, y_train_p):.4f}\")\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(f\"\\tValidation:\\t{mean_squared_error(y_valid, y_valid_p):.4f}\")\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(f\"\\tTest:\\t\\t{mean_squared_error(y_test, y_test_p):.4f}\")\n",
    "        \n",
    "        print(\"RMSE\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(f\"\\tTrain:\\t\\t{np.sqrt(mean_squared_error(y_train, y_train_p)):.4f}\")\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(f\"\\tValidation:\\t{np.sqrt(mean_squared_error(y_valid, y_valid_p)):.4f}\")\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(f\"\\tTest:\\t\\t{np.sqrt(mean_squared_error(y_test, y_test_p)):.4f}\")\n",
    "            \n",
    "    \n",
    "    if model_type == \"binary_class\":\n",
    "        print(\"Accuracy\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(f\"\\tTrain:\\t\\t{accuracy_score(y_train, y_train_p):.4f}\")\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(f\"\\tValidation:\\t{accuracy_score(y_valid, y_valid_p):.4f}\")\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(f\"\\tTest:\\t\\t{accuracy_score(y_test, y_test_p):.4f}\")\n",
    "\n",
    "        print(\"Precision\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(f\"\\tTrain:\\t\\t{precision_score(y_train, y_train_p):.4f}\")\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(f\"\\tValidation:\\t{precision_score(y_valid, y_valid_p):.4f}\")\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(f\"\\tTest:\\t\\t{precision_score(y_test, y_test_p):.4f}\")\n",
    "            \n",
    "        print(\"Recall\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(f\"\\tTrain:\\t\\t{recall_score(y_train, y_train_p):.4f}\")\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(f\"\\tValidation:\\t{recall_score(y_valid, y_valid_p):.4f}\")\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(f\"\\tTest:\\t\\t{recall_score(y_test, y_test_p):.4f}\")\n",
    "\n",
    "        print(\"F1 score\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(f\"\\tTrain:\\t\\t{f1_score(y_train, y_train_p):.4f}\")\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(f\"\\tValidation:\\t{f1_score(y_valid, y_valid_p):.4f}\")\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(f\"\\tTest:\\t\\t{f1_score(y_test, y_test_p):.4f}\")\n",
    "\n",
    "        print(\"\\n\\nClassification report\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(\"\\nTrain\")\n",
    "            print(classification_report(y_train, y_train_p, digits = 4))\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(\"\\nValid\")\n",
    "            print(classification_report(y_valid, y_valid_p, digits = 4))\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(\"\\nTest\")            \n",
    "            print(classification_report(y_test, y_test_p, digits = 4))\n",
    "\n",
    "                        \n",
    "    if model_type == \"multi_class\":\n",
    "        print(\"Accuracy\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(f\"\\tTrain:\\t\\t{accuracy_score(y_train, y_train_p):.4f}\")\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(f\"\\tValidation:\\t{accuracy_score(y_valid, y_valid_p):.4f}\")\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(f\"\\tTest:\\t\\t{accuracy_score(y_test, y_test_p):.4f}\")\n",
    "                       \n",
    "        print(\"\\n\\nClassification report\")\n",
    "        if y_train is not None and y_train_p is not None: \n",
    "            print(\"\\nTrain\")\n",
    "            print(classification_report(y_train, y_train_p, digits = 4))\n",
    "        if y_valid is not None and y_valid_p is not None: \n",
    "            print(\"\\nValid\")\n",
    "            print(classification_report(y_valid, y_valid_p, digits = 4))\n",
    "        if y_test is not None and y_test_p is not None: \n",
    "            print(\"\\nTest\")            \n",
    "            print(classification_report(y_test, y_test_p, digits = 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aeabcdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline performance metrics\n",
      "Model R2\n",
      "\tTrain:\t\t-0.9643\n",
      "\tValidation:\t-0.9852\n",
      "\tTest:\t\t-0.9613\n",
      "MAE\n",
      "\tTrain:\t\t0.4910\n",
      "\tValidation:\t0.4960\n",
      "\tTest:\t\t0.4900\n",
      "MSE\n",
      "\tTrain:\t\t0.4910\n",
      "\tValidation:\t0.4960\n",
      "\tTest:\t\t0.4900\n",
      "RMSE\n",
      "\tTrain:\t\t0.7007\n",
      "\tValidation:\t0.7043\n",
      "\tTest:\t\t0.7000\n"
     ]
    }
   ],
   "source": [
    "perf_mets(\n",
    "    y_train = y_train, y_train_p = y_train_p,\n",
    "    y_valid = y_valid, y_valid_p = y_valid_p,\n",
    "    y_test = y_test, y_test_p = y_test_p\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f91837a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline performance metrics\n",
      "Accuracy\n",
      "\tTrain:\t\t0.5185\n",
      "\tValidation:\t0.5020\n",
      "\tTest:\t\t0.4630\n",
      "Precision\n",
      "\tTrain:\t\t0.5251\n",
      "\tValidation:\t0.4975\n",
      "\tTest:\t\t0.4565\n",
      "Recall\n",
      "\tTrain:\t\t0.5350\n",
      "\tValidation:\t0.4975\n",
      "\tTest:\t\t0.4797\n",
      "F1 score\n",
      "\tTrain:\t\t0.5300\n",
      "\tValidation:\t0.4975\n",
      "\tTest:\t\t0.4678\n",
      "\n",
      "\n",
      "Classification report\n",
      "\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5114    0.5015    0.5064       985\n",
      "           1     0.5251    0.5350    0.5300      1015\n",
      "\n",
      "    accuracy                         0.5185      2000\n",
      "   macro avg     0.5183    0.5182    0.5182      2000\n",
      "weighted avg     0.5184    0.5185    0.5184      2000\n",
      "\n",
      "\n",
      "Valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5064    0.5064    0.5064      1009\n",
      "           1     0.4975    0.4975    0.4975       991\n",
      "\n",
      "    accuracy                         0.5020      2000\n",
      "   macro avg     0.5020    0.5020    0.5020      2000\n",
      "weighted avg     0.5020    0.5020    0.5020      2000\n",
      "\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4700    0.4469    0.4581       508\n",
      "           1     0.4565    0.4797    0.4678       492\n",
      "\n",
      "    accuracy                         0.4630      1000\n",
      "   macro avg     0.4632    0.4633    0.4630      1000\n",
      "weighted avg     0.4633    0.4630    0.4629      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perf_mets(\n",
    "    model_type = \"binary_class\",    \n",
    "    y_train = y_train, y_train_p = y_train_p,\n",
    "    y_valid = y_valid, y_valid_p = y_valid_p,\n",
    "    y_test = y_test, y_test_p = y_test_p\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b6674eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline performance metrics\n",
      "Accuracy\n",
      "\tTrain:\t\t0.4844\n",
      "\tValidation:\t0.4844\n",
      "\tTest:\t\t0.4844\n",
      "Precision\n",
      "\tTrain:\t\t0.4839\n",
      "\tValidation:\t0.4839\n",
      "\tTest:\t\t0.4839\n",
      "Recall\n",
      "\tTrain:\t\t0.4804\n",
      "\tValidation:\t0.4804\n",
      "\tTest:\t\t0.4804\n",
      "F1 score\n",
      "\tTrain:\t\t0.4821\n",
      "\tValidation:\t0.4821\n",
      "\tTest:\t\t0.4821\n",
      "\n",
      "\n",
      "Classification report\n",
      "\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4849    0.4884    0.4867      2502\n",
      "           1     0.4839    0.4804    0.4821      2498\n",
      "\n",
      "    accuracy                         0.4844      5000\n",
      "   macro avg     0.4844    0.4844    0.4844      5000\n",
      "weighted avg     0.4844    0.4844    0.4844      5000\n",
      "\n",
      "\n",
      "Valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4849    0.4884    0.4867      2502\n",
      "           1     0.4839    0.4804    0.4821      2498\n",
      "\n",
      "    accuracy                         0.4844      5000\n",
      "   macro avg     0.4844    0.4844    0.4844      5000\n",
      "weighted avg     0.4844    0.4844    0.4844      5000\n",
      "\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4849    0.4884    0.4867      2502\n",
      "           1     0.4839    0.4804    0.4821      2498\n",
      "\n",
      "    accuracy                         0.4844      5000\n",
      "   macro avg     0.4844    0.4844    0.4844      5000\n",
      "weighted avg     0.4844    0.4844    0.4844      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perf_mets(\n",
    "    model_type = \"binary_class\",\n",
    "    y_train = y, y_train_p = y_pred, \n",
    "    y_test = y, y_test_p = y_pred,\n",
    "    y_valid = y, y_valid_p = y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "729a58db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline performance metrics\n",
      "Accuracy\n",
      "\tTrain:\t\t0.2010\n",
      "\tValidation:\t0.1955\n",
      "\tTest:\t\t0.2080\n",
      "\n",
      "\n",
      "Classification report\n",
      "\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a     0.2030    0.2097    0.2063       391\n",
      "           b     0.2124    0.1980    0.2049       399\n",
      "           c     0.2069    0.2244    0.2153       401\n",
      "           d     0.1726    0.1655    0.1689       411\n",
      "           e     0.2101    0.2085    0.2093       398\n",
      "\n",
      "    accuracy                         0.2010      2000\n",
      "   macro avg     0.2010    0.2012    0.2010      2000\n",
      "weighted avg     0.2008    0.2010    0.2008      2000\n",
      "\n",
      "\n",
      "Valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a     0.1946    0.2047    0.1995       386\n",
      "           b     0.2038    0.2078    0.2058       409\n",
      "           c     0.1774    0.1734    0.1753       398\n",
      "           d     0.1935    0.1797    0.1864       395\n",
      "           e     0.2067    0.2112    0.2089       412\n",
      "\n",
      "    accuracy                         0.1955      2000\n",
      "   macro avg     0.1952    0.1954    0.1952      2000\n",
      "weighted avg     0.1953    0.1955    0.1953      2000\n",
      "\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a     0.2133    0.2286    0.2207       210\n",
      "           b     0.1779    0.1968    0.1869       188\n",
      "           c     0.1937    0.1787    0.1859       207\n",
      "           d     0.2344    0.2153    0.2244       209\n",
      "           e     0.2228    0.2204    0.2216       186\n",
      "\n",
      "    accuracy                         0.2080      1000\n",
      "   macro avg     0.2084    0.2080    0.2079      1000\n",
      "weighted avg     0.2088    0.2080    0.2081      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perf_mets(\n",
    "    model_type = \"multi_class\",    \n",
    "    y_train = y_train, y_train_p = y_train_p,\n",
    "    y_valid = y_valid, y_valid_p = y_valid_p,\n",
    "    y_test = y_test, y_test_p = y_test_p\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1e221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
